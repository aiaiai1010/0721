<!DOCTYPE html>
<html>
<head>
  <title>首＋姿勢検出</title>
  <style>
    body {
      font-size: 20px;
      text-align: center;
      margin: 0;
      padding: 0;
    }
    #content {
      display: flex;
      justify-content: center;
      gap: 10px;
      margin-top: 10px;
    }
    video, canvas {
      width: 320px;
      height: 240px;
      border: 1px solid #aaa;
    }
    #output, #warning {
      margin-top: 10px;
    }
    #warning {
      font-size: 24px;
      font-weight: bold;
    }
  </style>
</head>
<body>
  <h1>首の傾き検出</h1>
  <button id="startBtn">開始</button>
  <div id="output">準備中...</div>
  <div id="warning"></div>
  <div id="content">
    <video id="video" autoplay playsinline muted></video>
    <canvas id="canvas"></canvas>
  </div>

  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
  <script>
    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d');
    const out = document.getElementById('output');
    const warn = document.getElementById('warning');
    let pitch = 0, roll = 0;

    function handleOri(e) {
      pitch = e.beta;
      roll = e.gamma;
    }
    window.addEventListener('deviceorientation', handleOri);

    const faceMesh = new FaceMesh({
      locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`
    });

    faceMesh.setOptions({
      maxNumFaces: 1,
      minDetectionConfidence: 0.5,
      minTrackingConfidence: 0.5
    });

    faceMesh.onResults((results) => {
      if (!results.multiFaceLandmarks) {
        out.textContent = `傾き: ${pitch.toFixed(1)}°, ${roll.toFixed(1)}°\n顔未検出`;
        warn.textContent = "顔が検出できません";
        warn.style.color = 'red';
        return;
      }

      ctx.drawImage(results.image, 0, 0, canvas.width, canvas.height);
      const lm = results.multiFaceLandmarks[0];
      const nose = lm[1], chin = lm[152];
      const yDiff = chin.y - nose.y;

      const dir = yDiff < 0.13 ? '下を向き' : yDiff > 0.19 ? '上を向き' : 'まっすぐ';
      const bent = pitch <= 40 ? (dir !== '上') : (dir === '下');

      out.textContent = `Pitch: ${pitch.toFixed(1)}° Roll: ${roll.toFixed(1)}°\n顔: ${dir}`;
      warn.textContent = bent ? '首が曲がっています' : '首は自然です';
      warn.style.color = bent ? 'red' : 'green';
    });

    async function start() {
      const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'user' } });
      video.srcObject = stream;
      await new Promise((r) => video.onloadedmetadata = r);
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      new Camera(video, {
        onFrame: async () => {
          await faceMesh.send({ image: video });
        },
        width: 640,
        height: 480
      }).start();
      document.getElementById('startBtn').style.display = 'none';
    }

    document.getElementById('startBtn').onclick = start;
  </script>
</body>
</html>
